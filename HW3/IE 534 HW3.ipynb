{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Xinyan Yang \n",
    "### NetID: xinyany2\n",
    "**HW3: Train a deep convolution network on a GPU with PyTorch for the CIFAR10 dataset. The convolution network should use (A) dropout, (B) trained with RMSprop or ADAM, and (C) data augmentation. For 10% extra credit, compare dropout test accuracy (i) using the heuristic prediction rule and (ii) Monte Carlo simulation.**\n",
    "*For full credit, the model should achieve 80-90% Test Accuracy. Submit via Compass (1) the code and (2) a paragraph (in a PDF document) which reports the results and briefly describes the model architecture. Due September 28 at 5:00 PM.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The results and model architecture  \n",
    "\n",
    "The following code trains a convolution neural network on a GPU with Pytorch for the CIFAR10 dataset. We will do the following steps in order.  \n",
    "1. Load and normalizing the CIFAR10 training and test datasets using ``torchvision``  \n",
    "2. Define a Convolution Neural Network  \n",
    "3. Define a loss function  \n",
    "4. Train the network on the training data  \n",
    "5. Test the network on the test data \n",
    "  \n",
    "*Data augmention*(Random horizontal flip, random vertical flip and random rotation) is performed while loading the dataset. The deep cnn is composed of 8 convolution layers, 2 max-pooling layers and 2 fully-connected layers, at the same time *dropout* and *batch normalization* are performed every other layer.  The criterion for the loss function is CrossEntropyLoss and the optimizer is *Adam*.  \n",
    "  \n",
    " After 100 epochs , **the test accuracy is 84.29%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below output comes from the result of running the code on a GPU with BW. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "  \n",
    "--- Epoch :  1 ---  \n",
    "lr : 0.001000  \n",
    "Epoch [1/100], Step [100/500], Loss: 1.9017  \n",
    "Epoch [1/100], Step [200/500], Loss: 1.6356  \n",
    "Epoch [1/100], Step [300/500], Loss: 1.8095  \n",
    "Epoch [1/100], Step [400/500], Loss: 1.7006  \n",
    "Epoch [1/100], Step [500/500], Loss: 1.5524  \n",
    "Val Acc : 0.4356   \n",
    "  \n",
    "  \n",
    "--- Epoch : 21 ---  \n",
    "lr : 0.000810  \n",
    "Epoch [21/100], Step [100/500], Loss: 1.0175  \n",
    "Epoch [21/100], Step [200/500], Loss: 0.8192  \n",
    "Epoch [21/100], Step [300/500], Loss: 0.7113  \n",
    "Epoch [21/100], Step [400/500], Loss: 0.8276  \n",
    "Epoch [21/100], Step [500/500], Loss: 0.8906  \n",
    "Val Acc : 0.7641  \n",
    "  \n",
    "  \n",
    "--- Epoch : 41 ---  \n",
    "lr : 0.000656  \n",
    "Epoch [41/100], Step [100/500], Loss: 0.6814  \n",
    "Epoch [41/100], Step [200/500], Loss: 0.7379  \n",
    "Epoch [41/100], Step [300/500], Loss: 0.5427  \n",
    "Epoch [41/100], Step [400/500], Loss: 0.7138  \n",
    "Epoch [41/100], Step [500/500], Loss: 0.5250  \n",
    "Val Acc : 0.8070  \n",
    "  \n",
    "  \n",
    "--- Epoch : 61 ---  \n",
    "lr : 0.000531  \n",
    "Epoch [61/100], Step [100/500], Loss: 0.5049  \n",
    "Epoch [61/100], Step [200/500], Loss: 0.5073  \n",
    "Epoch [61/100], Step [300/500], Loss: 0.4406  \n",
    "Epoch [61/100], Step [400/500], Loss: 0.6080  \n",
    "Epoch [61/100], Step [500/500], Loss: 0.4265  \n",
    "Val Acc : 0.8243  \n",
    "  \n",
    "  \n",
    "--- Epoch : 81 ---  \n",
    "lr : 0.000430  \n",
    "Epoch [81/100], Step [100/500], Loss: 0.4927  \n",
    "Epoch [81/100], Step [200/500], Loss: 0.4958  \n",
    "Epoch [81/100], Step [300/500], Loss: 0.4971  \n",
    "Epoch [81/100], Step [400/500], Loss: 0.4501  \n",
    "Epoch [81/100], Step [500/500], Loss: 0.5944  \n",
    "Val Acc : 0.8381  \n",
    "  \n",
    "  \n",
    "--- Epoch : 100 ---  \n",
    "lr : 0.000387  \n",
    "Epoch [100/100], Step [100/500], Loss: 0.6904  \n",
    "Epoch [100/100], Step [200/500], Loss: 0.6240  \n",
    "Epoch [100/100], Step [300/500], Loss: 0.5897  \n",
    "Epoch [100/100], Step [400/500], Loss: 0.4948  \n",
    "Epoch [100/100], Step [500/500], Loss: 0.6030  \n",
    "Val Acc : 0.8429  \n",
    "  \n",
    "  \n",
    "Test Accuracy of the model on the 10000 test images: 84.29 %  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding: utf-8\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed\n",
    "torch.manual_seed(1)\n",
    "# Hyper parameters\n",
    "num_epochs = 80\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data.\n",
    "print('==> Preparing data..')\n",
    "\n",
    "# The output of dataset of torchvision is PILImage in [0,1], we normalize it first to [-1, 1] \n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Download and construct CIFAR-10 dataset.\n",
    "#dataloader, 组合数据集和采样器，并在数据集上提供单进程或多进程迭代器/batch_size:每批次进入多少数据/shuffle：shuffle the data\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                             train=True, \n",
    "                                             transform=transform_train,\n",
    "                                             download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                          train=False, \n",
    "                                          transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cifar10Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=4, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=4, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=4, stride=1, padding=2)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=4, stride=1, padding=2)\n",
    "        self.conv5 = nn.Conv2d(64, 64, kernel_size=4, stride=1, padding=2)\n",
    "        self.conv6 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv7 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv8 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
    "        self.fc2 = nn.Linear(500, num_classes)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(64)\n",
    "        self.batchnorm5 = nn.BatchNorm2d(64)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.25)\n",
    "        self.dropout3 = nn.Dropout2d(0.25)\n",
    "        self.dropout4 = nn.Dropout2d(0.5)\n",
    "           \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = self.batchnorm5(x)\n",
    "        x = self.dropout4(x)   \n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        return self.fc2(x)\n",
    "\n",
    "model = Cifar10Model().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss fucntion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\t\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "\n",
    "def train(epoch, writer):\n",
    "    model.train()\n",
    "    scheduler.step()\n",
    "    with open('out.txt', 'w') as f:\n",
    "    \n",
    "    print(\"\\n--- Epoch : %2d ---\" % epoch, file = f)\n",
    "    print(\"lr : %f\" % optimizer.param_groups[0]['lr'], file = f)\n",
    "     \n",
    "    steps = 50000//batch_size\n",
    "    \n",
    "    #avoid the overflow error in bluewater\n",
    "    if(epoch > 6):\n",
    "        for group in optimizer.param_groups:\n",
    "            for p in group['params']:\n",
    "                state = optimizer.state[p]\n",
    "                if(state['step'] >= 1024):\n",
    "                    state['step'] = 1000\n",
    "    optimizer.step()\n",
    "    \n",
    "    for step, (images, labels) in enumerate(train_loader, 1):\n",
    "        global global_step\n",
    "        global_step += 1\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' % (epoch, epochs, step, steps, loss.item()), file = f)\n",
    "            writer.add_scalar('train/train_loss', loss.item() , global_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(epoch, writer):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    print(\"Val Acc : %.4f\" % (correct/total), file = f)\n",
    "    writer.add_scalar('eval/val_acc', correct*100/total, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "epochs = 1\n",
    " \n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train(epoch, writer)\n",
    "    eval(epoch, writer)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_cifar10_nobatch.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total), file = f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

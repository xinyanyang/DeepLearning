{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Xinyan Yang \n",
    "\n",
    "### NetID: xinyany2\n",
    "\n",
    "##### HW2: Implement and train a convolution neural network from scratch in Python for the MNIST dataset (no PyTorch). You should write your own code for convolutions (e.g., do not use SciPy's convolution function). The convolution network should have a single hidden layer with multiple channels. \n",
    "\n",
    "*For full credit, submit via Compass (1) the code and (2) a paragraph (in a PDF document) which states the Test Accuracy and briefly describes the implementation. Due September 14 at 5:00 PM.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code implements the backpropogation algorithm to build a convolution neural network from scratch. It is composed of a forward step and a backward step. In the forward step, the output f(X;θ) and intermediary network values (Z,H,and U) are calculated. To calculate Z, three for loops were built to realize the convolution of X and K. Then I choose the sigmoid activation function for the nonlinearities σ(z). In the backward step, the gradient with respect to the parameters θ is calculated. The backward step relies upon the values calculated in the forward step.\n",
    "\n",
    "I set the size of filter to be 5, used 3 channels and 10 epochs , **the test accuracy is 97.34%**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding: utf-8\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import copy\n",
    "from random import randint\n",
    "import random\n",
    "\n",
    "#load MNIST data\n",
    "MNIST_data = h5py.File('MNISTdata.hdf5', 'r')\n",
    "x_train = np.float32(MNIST_data['x_train'][:] )\n",
    "y_train = np.int32(np.array(MNIST_data['y_train'][:,0]))\n",
    "x_test = np.float32( MNIST_data['x_test'][:] )\n",
    "y_test = np.int32( np.array( MNIST_data['y_test'][:,0] ) )\n",
    "MNIST_data.close()\n",
    "\n",
    "#Implementation of stochastic gradient descent algorithm\n",
    "#number of inputs\n",
    "num_inputs = 28\n",
    "#number of outputs\n",
    "num_outputs = 10\n",
    "#the size of the filter k_y * k_x\n",
    "filter_size = 5\n",
    "#number of channels\n",
    "num_channel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize parameters K, W, b\n",
    "model = {}\n",
    "model['K'] = np.random.randn(num_channel,filter_size,filter_size) / 28\n",
    "model['W'] = np.random.randn(num_outputs, num_inputs-filter_size+1, num_inputs-filter_size+1,num_channel) / 28\n",
    "model['b'] = np.random.randn(num_outputs) / 28\n",
    "model_grads = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_function(z):\n",
    "    ZZ = np.exp(z)/np.sum(np.exp(z))\n",
    "    return ZZ\n",
    "\n",
    "def e(y, num_outputs=10):\n",
    "    \"\"\"\n",
    "    e(y) function\n",
    "    \"\"\"\n",
    "    ret = np.zeros(num_outputs, dtype=np.int)\n",
    "    ret[y] = 1.0\n",
    "    return ret  \n",
    "    \n",
    "def forward(x,y,model):\n",
    "    x = x.reshape(num_inputs,num_inputs)\n",
    "    Z = np.zeros((num_channel, num_inputs-filter_size+1, num_inputs-filter_size+1))\n",
    "   \n",
    "    for p in range(num_channel):\n",
    "        for i in range(num_inputs-filter_size+1):\n",
    "            for j in range(num_inputs-filter_size+1):\n",
    "                mul_x = x[i:i+filter_size, j:j+filter_size]\n",
    "                Z[p][i][j] = np.tensordot(mul_x, model['K'][p], axes=2)\n",
    "    #implement the sigmoid activation function\n",
    "    H = 1/(np.exp(-Z) + 1)\n",
    "    H = H.reshape(num_inputs-filter_size+1, num_inputs-filter_size+1, num_channel)\n",
    "    W_mul_H = np.zeros(num_outputs)\n",
    "    for k in range(num_outputs):\n",
    "        W_mul_H[k] = np.sum(np.multiply(model['W'][k], H))\n",
    "    U = W_mul_H + model['b']\n",
    "    p = softmax_function(U)\n",
    "    return Z,H,p\n",
    "\n",
    "def backward(x, y, p, H, Z, model, model_grads):\n",
    "    x = x.reshape(num_inputs,num_inputs)\n",
    "    dU = -e(y) + p\n",
    "    delta = np.zeros((num_inputs-filter_size+1, num_inputs-filter_size+1,num_channel))\n",
    "    for k in range(num_outputs):\n",
    "        delta = delta + dU.reshape(num_outputs)[k]*model['W'][k]\n",
    "    sigma_z_der = np.multiply(H,(1-H))\n",
    "    sigmaz_delta = np.multiply(sigma_z_der, delta)\n",
    "    sigmaz_delta = sigmaz_delta.reshape(num_channel,num_inputs-filter_size+1,num_inputs-filter_size+1)\n",
    "    for p in range(num_channel):\n",
    "        for i in range(filter_size):\n",
    "            for j in range(filter_size):          \n",
    "                mul_x2 = x[i:i+num_inputs-filter_size+1, j:j+num_inputs-filter_size+1]\n",
    "                model_grads['K'][p][i][j] = np.tensordot(mul_x2, sigmaz_delta[p], axes=2)\n",
    "    model_grads['b'] = dU\n",
    "    for k in range(num_outputs):\n",
    "        model_grads['W'][k] = dU.reshape(num_outputs)[k] * H\n",
    "    return model_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0  | Training Accuracy: 0.8772\n",
      "epochs: 1  | Training Accuracy: 0.9456\n",
      "epochs: 2  | Training Accuracy: 0.9569\n",
      "epochs: 3  | Training Accuracy: 0.9622166666666667\n",
      "epochs: 4  | Training Accuracy: 0.9671833333333333\n",
      "epochs: 5  | Training Accuracy: 0.96905\n",
      "epochs: 6  | Training Accuracy: 0.9848166666666667\n",
      "epochs: 7  | Training Accuracy: 0.9863\n",
      "epochs: 8  | Training Accuracy: 0.9864833333333334\n",
      "epochs: 9  | Training Accuracy: 0.9875666666666667\n"
     ]
    }
   ],
   "source": [
    "LR = 0.1\n",
    "num_epochs = 10\n",
    "for epochs in range(num_epochs):\n",
    "    #Learning rate schedule\n",
    "    if (epochs > 5):\n",
    "        LR = 0.01\n",
    "    total_correct = 0\n",
    "    for n in range(len(x_train)):\n",
    "        n_random = randint(0,len(x_train)-1 )\n",
    "        y = y_train[n_random]\n",
    "        x = x_train[n_random][:]\n",
    "        Z,H,p = forward(x, y, model)\n",
    "        prediction = np.argmax(p)\n",
    "        if (prediction == y):\n",
    "            total_correct += 1\n",
    "        model_grads = backward(x, y, p, H, Z, model, model_grads)\n",
    "        #update parameters\n",
    "        model['K'] = model['K'] - LR*model_grads['K']\n",
    "        model['b'] = model['b'] - LR*model_grads['b']\n",
    "        model['W'] = model['W'] - LR*model_grads['W']\n",
    "        \n",
    "    print('epochs: '+ str(epochs), ' | Training Accuracy: ' + str(total_correct/np.float(len(x_train))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9734\n"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "total_correct = 0\n",
    "for n in range( len(x_test)):\n",
    "    y = y_test[n]\n",
    "    x = x_test[n][:]\n",
    "    Z,H,p = forward(x, y, model)\n",
    "    prediction = np.argmax(p)\n",
    "    if (prediction == y):\n",
    "        total_correct += 1\n",
    "print('Test Accuracy:', total_correct/np.float(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
